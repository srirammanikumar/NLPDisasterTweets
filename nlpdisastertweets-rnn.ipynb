{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":2,"outputs":[{"output_type":"stream","text":"/kaggle/input/nlp-getting-started/train.csv\n/kaggle/input/nlp-getting-started/test.csv\n/kaggle/input/nlp-getting-started/sample_submission.csv\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')\nout_df = pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')\ntrain_df.head(10)","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"   id keyword location                                               text  \\\n0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n5   8     NaN      NaN  #RockyFire Update => California Hwy. 20 closed...   \n6  10     NaN      NaN  #flood #disaster Heavy rain causes flash flood...   \n7  13     NaN      NaN  I'm on top of the hill and I can see a fire in...   \n8  14     NaN      NaN  There's an emergency evacuation happening now ...   \n9  15     NaN      NaN  I'm afraid that the tornado is coming to our a...   \n\n   target  \n0       1  \n1       1  \n2       1  \n3       1  \n4       1  \n5       1  \n6       1  \n7       1  \n8       1  \n9       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Our Deeds are the Reason of this #earthquake M...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>All residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>8</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>#RockyFire Update =&gt; California Hwy. 20 closed...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>10</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>#flood #disaster Heavy rain causes flash flood...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>13</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>I'm on top of the hill and I can see a fire in...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>14</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>There's an emergency evacuation happening now ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>15</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>I'm afraid that the tornado is coming to our a...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# remove all NaN \ntrain_df = train_df.fillna(0)\nout_df = out_df.fillna(0)\ntrain_df.head(10)","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"   id keyword location                                               text  \\\n0   1       0        0  Our Deeds are the Reason of this #earthquake M...   \n1   4       0        0             Forest fire near La Ronge Sask. Canada   \n2   5       0        0  All residents asked to 'shelter in place' are ...   \n3   6       0        0  13,000 people receive #wildfires evacuation or...   \n4   7       0        0  Just got sent this photo from Ruby #Alaska as ...   \n5   8       0        0  #RockyFire Update => California Hwy. 20 closed...   \n6  10       0        0  #flood #disaster Heavy rain causes flash flood...   \n7  13       0        0  I'm on top of the hill and I can see a fire in...   \n8  14       0        0  There's an emergency evacuation happening now ...   \n9  15       0        0  I'm afraid that the tornado is coming to our a...   \n\n   target  \n0       1  \n1       1  \n2       1  \n3       1  \n4       1  \n5       1  \n6       1  \n7       1  \n8       1  \n9       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Our Deeds are the Reason of this #earthquake M...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>All residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>0</td>\n      <td>0</td>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>8</td>\n      <td>0</td>\n      <td>0</td>\n      <td>#RockyFire Update =&gt; California Hwy. 20 closed...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>10</td>\n      <td>0</td>\n      <td>0</td>\n      <td>#flood #disaster Heavy rain causes flash flood...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>13</td>\n      <td>0</td>\n      <td>0</td>\n      <td>I'm on top of the hill and I can see a fire in...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>14</td>\n      <td>0</td>\n      <td>0</td>\n      <td>There's an emergency evacuation happening now ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>15</td>\n      <td>0</td>\n      <td>0</td>\n      <td>I'm afraid that the tornado is coming to our a...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import *\n\nimport re\nfrom bs4 import BeautifulSoup\n\ndef format_tweets(tweet):\n    \n    text = BeautifulSoup(tweet, \"html.parser\").get_text() # Remove HTML tags\n    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower()) # Convert to lower case\n        \n    return text\n\n","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from string import punctuation\n\ntweets_train = [format_tweets(tweet) for tweet in train_df.text]\n    \ntweets_train[10]","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"'three people died from the heat wave so far'"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_text = ' '.join(tweets_train)\n\n# create a list of words\nwords = all_text.split()","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import Counter\n\nNO_WORD = 14999\n\ndef get_int(word, vocab_to_int):\n    return vocab_to_int[word] if word in vocab_to_int else NO_WORD\n    \n## Build a dictionary that maps words to integers\ncounts = Counter(words) # get count of each word\nvocab = sorted(counts, key=counts.get, reverse=True)\nvocab_to_int = {word: ii for ii, word in enumerate(vocab[:14998], 1)}\n\n## use the dict to tokenize each review in reviews_split\n## store the tokenized reviews in reviews_ints\ntweets_ints = []\nfor tweet in tweets_train:\n    tweets_ints.append([get_int(word, vocab_to_int) for word in tweet.split()])\n    \n    \n","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vocab_to_int","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"{'t': 1,\n 'co': 2,\n 'http': 3,\n 'the': 4,\n 'a': 5,\n 'in': 6,\n 'to': 7,\n 'of': 8,\n 'i': 9,\n 'and': 10,\n 's': 11,\n 'is': 12,\n 'you': 13,\n 'for': 14,\n 'on': 15,\n 'it': 16,\n 'my': 17,\n 'that': 18,\n 'with': 19,\n 'at': 20,\n 'by': 21,\n 'this': 22,\n 'from': 23,\n 'https': 24,\n 'be': 25,\n 'are': 26,\n 'was': 27,\n 'have': 28,\n 'like': 29,\n 'as': 30,\n 'up': 31,\n 'me': 32,\n 'just': 33,\n 'but': 34,\n 'so': 35,\n 'm': 36,\n 'we': 37,\n 'not': 38,\n 'your': 39,\n 'out': 40,\n 'all': 41,\n 'no': 42,\n 'after': 43,\n 'will': 44,\n 'when': 45,\n 'fire': 46,\n 'can': 47,\n 'an': 48,\n 'has': 49,\n 'if': 50,\n 'he': 51,\n 'they': 52,\n 'get': 53,\n 'new': 54,\n 'now': 55,\n 'what': 56,\n 'via': 57,\n 'more': 58,\n '2': 59,\n 'about': 60,\n 'or': 61,\n 'people': 62,\n 'news': 63,\n 'one': 64,\n 'how': 65,\n 'don': 66,\n 'been': 67,\n 'who': 68,\n 'over': 69,\n 'there': 70,\n 'into': 71,\n 're': 72,\n 'do': 73,\n 'video': 74,\n 'disaster': 75,\n 'emergency': 76,\n 'police': 77,\n 'than': 78,\n 'would': 79,\n '3': 80,\n 'her': 81,\n 'u': 82,\n 'body': 83,\n 'his': 84,\n 'some': 85,\n 'still': 86,\n 'us': 87,\n 'were': 88,\n 'california': 89,\n 'storm': 90,\n 'burning': 91,\n 'crash': 92,\n 'back': 93,\n '1': 94,\n 'suicide': 95,\n 'day': 96,\n 'man': 97,\n 'time': 98,\n 'off': 99,\n 'them': 100,\n 'why': 101,\n 'got': 102,\n 'know': 103,\n 'rt': 104,\n 'had': 105,\n 'buildings': 106,\n 'first': 107,\n 'world': 108,\n 'see': 109,\n 'bomb': 110,\n 'going': 111,\n 'nuclear': 112,\n 'two': 113,\n 'love': 114,\n 'fires': 115,\n 'our': 116,\n 'attack': 117,\n 'today': 118,\n 'dead': 119,\n 'here': 120,\n 'killed': 121,\n 'year': 122,\n 'youtube': 123,\n 'go': 124,\n '4': 125,\n '5': 126,\n 'car': 127,\n 'their': 128,\n 'full': 129,\n 'train': 130,\n 'hiroshima': 131,\n 'life': 132,\n 'war': 133,\n 'old': 134,\n 'being': 135,\n 'd': 136,\n 'let': 137,\n 'may': 138,\n 'accident': 139,\n 'only': 140,\n 'good': 141,\n 'down': 142,\n 'families': 143,\n 'say': 144,\n 'think': 145,\n '2015': 146,\n 'she': 147,\n 'watch': 148,\n 've': 149,\n 'many': 150,\n 'last': 151,\n 'could': 152,\n 'home': 153,\n 'its': 154,\n 'way': 155,\n 'did': 156,\n 'make': 157,\n 'want': 158,\n 'then': 159,\n 'years': 160,\n 'w': 161,\n 'too': 162,\n 'collapse': 163,\n 'best': 164,\n 'death': 165,\n 'work': 166,\n 'help': 167,\n 'because': 168,\n 'mass': 169,\n 'look': 170,\n 'please': 171,\n 'even': 172,\n 'am': 173,\n 'another': 174,\n 'need': 175,\n 'army': 176,\n 'take': 177,\n 'wildfire': 178,\n 'mh370': 179,\n 'really': 180,\n 'lol': 181,\n 'should': 182,\n 'bombing': 183,\n 'him': 184,\n 'school': 185,\n 'black': 186,\n 'right': 187,\n 'll': 188,\n 'those': 189,\n 'fatal': 190,\n 'hot': 191,\n 'forest': 192,\n 'water': 193,\n '8': 194,\n 'pm': 195,\n '11': 196,\n 'obama': 197,\n 'much': 198,\n 'city': 199,\n 'read': 200,\n 'northern': 201,\n 'reddit': 202,\n 'live': 203,\n 'never': 204,\n 'great': 205,\n '9': 206,\n 'god': 207,\n 'where': 208,\n 'homes': 209,\n 'legionnaires': 210,\n 'bomber': 211,\n 'wreck': 212,\n 'latest': 213,\n 'japan': 214,\n 'every': 215,\n '6': 216,\n 'any': 217,\n 'typhoon': 218,\n 'flood': 219,\n 'atomic': 220,\n 'flames': 221,\n 'everyone': 222,\n 'said': 223,\n 'fear': 224,\n 'content': 225,\n 'floods': 226,\n 'near': 227,\n 'getting': 228,\n 'damage': 229,\n 'shit': 230,\n 'im': 231,\n 'ever': 232,\n 'come': 233,\n 'under': 234,\n 'injured': 235,\n 'top': 236,\n 'while': 237,\n 'feel': 238,\n 'most': 239,\n 'state': 240,\n 'hit': 241,\n 'since': 242,\n 'hope': 243,\n 'cross': 244,\n 'oil': 245,\n 'before': 246,\n '15': 247,\n 'found': 248,\n 'weather': 249,\n '10': 250,\n 'military': 251,\n 'coming': 252,\n 'night': 253,\n 'next': 254,\n 'stop': 255,\n 'during': 256,\n 'without': 257,\n 'ass': 258,\n 'earthquake': 259,\n 'evacuation': 260,\n 'flooding': 261,\n 'these': 262,\n 'truck': 263,\n 'debris': 264,\n 'little': 265,\n 'wild': 266,\n 'malaysia': 267,\n 'area': 268,\n 'times': 269,\n 'which': 270,\n 'well': 271,\n '7': 272,\n 'plan': 273,\n 'smoke': 274,\n 'heat': 275,\n 'set': 276,\n '08': 277,\n 'face': 278,\n 'cause': 279,\n 'movie': 280,\n 'wounded': 281,\n 'lightning': 282,\n 'thunderstorm': 283,\n 'rain': 284,\n 'check': 285,\n 'run': 286,\n 'food': 287,\n 'high': 288,\n 'through': 289,\n 'confirmed': 290,\n 'severe': 291,\n 'always': 292,\n 'fucking': 293,\n 'explosion': 294,\n 'looks': 295,\n 'bad': 296,\n 'weapon': 297,\n 'made': 298,\n 'sinking': 299,\n 'bloody': 300,\n 'p': 301,\n 'services': 302,\n 'blood': 303,\n '70': 304,\n 'change': 305,\n 'warning': 306,\n 'hail': 307,\n 'says': 308,\n 'hurricane': 309,\n 'natural': 310,\n 'devastated': 311,\n 'thunder': 312,\n 'until': 313,\n 'also': 314,\n 'free': 315,\n 'family': 316,\n 'house': 317,\n 'red': 318,\n 'liked': 319,\n 'fall': 320,\n 'weapons': 321,\n 'bags': 322,\n 'spill': 323,\n 'injuries': 324,\n 'refugees': 325,\n 'loud': 326,\n 'photo': 327,\n 'gonna': 328,\n 'summer': 329,\n 'end': 330,\n 'head': 331,\n 'tonight': 332,\n 'injury': 333,\n 'someone': 334,\n 'screaming': 335,\n 'boy': 336,\n 'again': 337,\n 'missing': 338,\n 'evacuate': 339,\n 'china': 340,\n 'murder': 341,\n 'air': 342,\n 'terrorism': 343,\n 'big': 344,\n 'wind': 345,\n 'failure': 346,\n 'trapped': 347,\n 'collided': 348,\n 'rescue': 349,\n 'fatalities': 350,\n 'sinkhole': 351,\n 'destroy': 352,\n 'whole': 353,\n 'save': 354,\n 'survive': 355,\n 'girl': 356,\n 'saudi': 357,\n 'released': 358,\n 'attacked': 359,\n 'bag': 360,\n 'explode': 361,\n 'hazard': 362,\n 'derailment': 363,\n 'harm': 364,\n 'collision': 365,\n 'deaths': 366,\n 'migrants': 367,\n 'panic': 368,\n 'wreckage': 369,\n 'outbreak': 370,\n 'breaking': 371,\n 'week': 372,\n 'around': 373,\n '30': 374,\n 'n': 375,\n '40': 376,\n 'o': 377,\n 'ambulance': 378,\n 'destruction': 379,\n 'long': 380,\n '05': 381,\n 'destroyed': 382,\n 'real': 383,\n 'post': 384,\n 'terrorist': 385,\n 'bridge': 386,\n 'rescued': 387,\n 'windstorm': 388,\n 'other': 389,\n 'update': 390,\n 'burned': 391,\n 'r': 392,\n 'does': 393,\n 'road': 394,\n 'game': 395,\n 'island': 396,\n 'trauma': 397,\n 'survivors': 398,\n 'women': 399,\n 'charged': 400,\n 'fuck': 401,\n 'story': 402,\n 'battle': 403,\n 'keep': 404,\n 'report': 405,\n 'bombed': 406,\n 'rescuers': 407,\n 'lives': 408,\n 'drought': 409,\n 'landslide': 410,\n 'survived': 411,\n 'twister': 412,\n 'wrecked': 413,\n 'county': 414,\n 'airplane': 415,\n 'call': 416,\n 'ok': 417,\n 'self': 418,\n 'away': 419,\n 'show': 420,\n 'against': 421,\n 'white': 422,\n 'displaced': 423,\n 'boat': 424,\n 'ruin': 425,\n 'service': 426,\n 'catastrophe': 427,\n 'crush': 428,\n 'deluge': 429,\n 'dust': 430,\n 'hostages': 431,\n 'sunk': 432,\n 'bus': 433,\n 'thing': 434,\n 'crashed': 435,\n 'phone': 436,\n 'august': 437,\n '0': 438,\n 'armageddon': 439,\n 'violent': 440,\n 'things': 441,\n 'twitter': 442,\n 'woman': 443,\n 'put': 444,\n 'half': 445,\n 'riot': 446,\n 'hazardous': 447,\n 'collapsed': 448,\n 'curfew': 449,\n 'danger': 450,\n 'devastation': 451,\n 'famine': 452,\n 'investigators': 453,\n 'massacre': 454,\n 'bang': 455,\n 'mudslide': 456,\n 'quarantine': 457,\n 'structural': 458,\n 'sandstorm': 459,\n 'whirlwind': 460,\n 'wave': 461,\n 'better': 462,\n 'least': 463,\n 'came': 464,\n 'suspect': 465,\n 'kills': 466,\n 'iran': 467,\n 'apocalypse': 468,\n 'b': 469,\n 'saw': 470,\n 'mosque': 471,\n 'hostage': 472,\n 'wanna': 473,\n 'tragedy': 474,\n 'rioting': 475,\n 'traumatised': 476,\n 'chemical': 477,\n 'derailed': 478,\n 'drowning': 479,\n 'engulfed': 480,\n 'screamed': 481,\n 'quarantined': 482,\n 'tornado': 483,\n 'horrible': 484,\n 'past': 485,\n 'heard': 486,\n 'national': 487,\n 'heart': 488,\n 'tomorrow': 489,\n 'part': 490,\n 'group': 491,\n 'power': 492,\n 'fedex': 493,\n 'oh': 494,\n 'bleeding': 495,\n 'light': 496,\n 'blown': 497,\n 'anniversary': 498,\n 'casualties': 499,\n 'cliff': 500,\n 'hundreds': 501,\n 'stock': 502,\n 'derail': 503,\n 'desolation': 504,\n 'detonate': 505,\n 'tsunami': 506,\n 'exploded': 507,\n 'hijacker': 508,\n 'inundated': 509,\n 'screams': 510,\n 'use': 511,\n 'left': 512,\n 'meltdown': 513,\n 'plane': 514,\n 'must': 515,\n 'went': 516,\n 'blew': 517,\n 'drown': 518,\n 'catastrophic': 519,\n 'wounds': 520,\n 'trouble': 521,\n 'electrocuted': 522,\n 'fatality': 523,\n 'flattened': 524,\n 'lava': 525,\n 'pandemonium': 526,\n 'razed': 527,\n 'st': 528,\n 'something': 529,\n 'thank': 530,\n 'reunion': 531,\n 'ebay': 532,\n 'lot': 533,\n 'zone': 534,\n 'soon': 535,\n 'calgary': 536,\n 'bioterror': 537,\n 'land': 538,\n 'bagging': 539,\n '00': 540,\n 'caused': 541,\n 'affected': 542,\n 'collide': 543,\n 'isis': 544,\n 'demolish': 545,\n 'demolition': 546,\n 'volcano': 547,\n 'evacuated': 548,\n 'hellfire': 549,\n 'murderer': 550,\n 'panicking': 551,\n 'south': 552,\n 'cool': 553,\n 'very': 554,\n 'minute': 555,\n 'doing': 556,\n 'possible': 557,\n 'sure': 558,\n 'river': 559,\n 'kill': 560,\n 'e': 561,\n 'c': 562,\n 'blazing': 563,\n 'song': 564,\n 'market': 565,\n 'send': 566,\n 'baby': 567,\n 'casualty': 568,\n 'cyclone': 569,\n 'hijacking': 570,\n 'rainstorm': 571,\n 'siren': 572,\n 'due': 573,\n 'three': 574,\n 'care': 575,\n 'kids': 576,\n 'traffic': 577,\n 'america': 578,\n 'goes': 579,\n 'men': 580,\n 'government': 581,\n 'annihilated': 582,\n 'thought': 583,\n 'arson': 584,\n 'officials': 585,\n 'india': 586,\n 'beautiful': 587,\n 'longer': 588,\n 'security': 589,\n 'pkk': 590,\n 'responders': 591,\n 'crushed': 592,\n 'detonation': 593,\n 'drowned': 594,\n 'obliterated': 595,\n 'detonated': 596,\n 'building': 597,\n 'thanks': 598,\n 'used': 599,\n 'issues': 600,\n 'same': 601,\n 'airport': 602,\n 'fight': 603,\n 'fan': 604,\n 'sound': 605,\n 'stay': 606,\n 'yet': 607,\n 'music': 608,\n 'nothing': 609,\n 'ur': 610,\n 'shoulder': 611,\n 'bush': 612,\n 'officer': 613,\n 'blast': 614,\n 'demolished': 615,\n 'electrocute': 616,\n 'eyewitness': 617,\n 'prebreak': 618,\n 'obliterate': 619,\n 'obliteration': 620,\n 'days': 621,\n 'ablaze': 622,\n '16': 623,\n 'shooting': 624,\n 'few': 625,\n 'already': 626,\n 'making': 627,\n 'done': 628,\n 'believe': 629,\n 'sirens': 630,\n 'fun': 631,\n 'hours': 632,\n 'start': 633,\n 'media': 634,\n 'remember': 635,\n '50': 636,\n 'offensive': 637,\n 'stretcher': 638,\n 'upheaval': 639,\n 'died': 640,\n 'far': 641,\n 'second': 642,\n 'inside': 643,\n 'leave': 644,\n 'actually': 645,\n 'wake': 646,\n 'peace': 647,\n 'israeli': 648,\n 'person': 649,\n 'avalanche': 650,\n 'having': 651,\n 'bioterrorism': 652,\n 'words': 653,\n 'blight': 654,\n 'policy': 655,\n 'such': 656,\n 'turkey': 657,\n 'mp': 658,\n 'seismic': 659,\n 'hijack': 660,\n 'sue': 661,\n 'snowstorm': 662,\n '16yr': 663,\n 'both': 664,\n 'site': 665,\n 'shot': 666,\n 'north': 667,\n '06': 668,\n 'support': 669,\n 'plans': 670,\n 'die': 671,\n 'play': 672,\n 'ago': 673,\n 'stand': 674,\n 'order': 675,\n 'trying': 676,\n 'lab': 677,\n 'health': 678,\n 'yes': 679,\n 'abc': 680,\n 'pic': 681,\n 'line': 682,\n 'nearby': 683,\n '25': 684,\n 'deluged': 685,\n 'declares': 686,\n 'reactor': 687,\n 'place': 688,\n 'wait': 689,\n 'west': 690,\n 'nowplaying': 691,\n 'didn': 692,\n 'gets': 693,\n 'yourself': 694,\n 'brown': 695,\n 'won': 696,\n 'horror': 697,\n 'history': 698,\n 'x': 699,\n 'children': 700,\n 'tv': 701,\n 'anything': 702,\n 'yeah': 703,\n 'guys': 704,\n 'deal': 705,\n 'doesn': 706,\n 'low': 707,\n 'find': 708,\n 'memories': 709,\n 'soudelor': 710,\n '01': 711,\n 'islam': 712,\n 'rubble': 713,\n 'swallowed': 714,\n 'lost': 715,\n 'outside': 716,\n 'tell': 717,\n 'job': 718,\n 'almost': 719,\n 'aircraft': 720,\n 'helicopter': 721,\n 'pakistan': 722,\n 'hey': 723,\n 'country': 724,\n 'bc': 725,\n 'hell': 726,\n 'maybe': 727,\n 'data': 728,\n 'own': 729,\n 'american': 730,\n 'business': 731,\n 'photos': 732,\n 'watching': 733,\n 'bigger': 734,\n 'rise': 735,\n 'desolate': 736,\n 'saipan': 737,\n 'hat': 738,\n 'conclusively': 739,\n '20': 740,\n 'street': 741,\n 'side': 742,\n 'happy': 743,\n 'center': 744,\n 'book': 745,\n 'anyone': 746,\n 'reuters': 747,\n 'bar': 748,\n 'pick': 749,\n 'control': 750,\n 'makes': 751,\n 'team': 752,\n 'literally': 753,\n 'transport': 754,\n 'searching': 755,\n 'blizzard': 756,\n 'money': 757,\n 'hear': 758,\n 'crews': 759,\n 'waves': 760,\n 'bodies': 761,\n 'projected': 762,\n 'bestnaijamade': 763,\n 'la': 764,\n 'rd': 765,\n 'finally': 766,\n 'property': 767,\n 'guy': 768,\n 'might': 769,\n 'eyes': 770,\n '12': 771,\n 'everything': 772,\n 'annihilation': 773,\n 'amid': 774,\n 'blaze': 775,\n 'damn': 776,\n 'feeling': 777,\n 'listen': 778,\n 'space': 779,\n 'hollywood': 780,\n 'pretty': 781,\n 'move': 782,\n 'online': 783,\n 'though': 784,\n 'morning': 785,\n 'probably': 786,\n 'aug': 787,\n 'myself': 788,\n 'saved': 789,\n 'trains': 790,\n 'signs': 791,\n 'effect': 792,\n 'manslaughter': 793,\n 'trench': 794,\n 'hailstorm': 795,\n '13': 796,\n 'fast': 797,\n 'arsonist': 798,\n 'mom': 799,\n 'aftershock': 800,\n 'once': 801,\n 'wrong': 802,\n 'feared': 803,\n '17': 804,\n 'hate': 805,\n 'sorry': 806,\n 'seen': 807,\n 'case': 808,\n 'major': 809,\n 'child': 810,\n 'name': 811,\n 'crisis': 812,\n 'leather': 813,\n 'caught': 814,\n 'town': 815,\n 'okay': 816,\n 'youth': 817,\n 'australia': 818,\n 'nearly': 819,\n 'spot': 820,\n 'image': 821,\n 'sensor': 822,\n 'refugio': 823,\n 'costlier': 824,\n 'miners': 825,\n 'heavy': 826,\n 'flash': 827,\n 'flag': 828,\n 'cars': 829,\n 'lord': 830,\n 'huge': 831,\n 'vehicle': 832,\n 'daily': 833,\n 'jobs': 834,\n 'omg': 835,\n 'ship': 836,\n 'crazy': 837,\n 'ball': 838,\n 'usa': 839,\n 'called': 840,\n 'class': 841,\n 'isn': 842,\n 'east': 843,\n 'ca': 844,\n 'texas': 845,\n 'worst': 846,\n 'needs': 847,\n 'fukushima': 848,\n 'wow': 849,\n 'russian': 850,\n 'giant': 851,\n '60': 852,\n 'angry': 853,\n 'course': 854,\n 'uk': 855,\n 'banned': 856,\n 'knock': 857,\n 'picking': 858,\n 'mayhem': 859,\n 'reason': 860,\n 'closed': 861,\n 'across': 862,\n 'haha': 863,\n 'hard': 864,\n 'others': 865,\n 'talk': 866,\n 'win': 867,\n 'official': 868,\n 'sign': 869,\n 'poor': 870,\n 'action': 871,\n 'toddler': 872,\n 'united': 873,\n 'blue': 874,\n 'gun': 875,\n 'star': 876,\n 'anthrax': 877,\n 'running': 878,\n 'looking': 879,\n 'computers': 880,\n 'dont': 881,\n 'follow': 882,\n 'entire': 883,\n 'level': 884,\n 'pay': 885,\n 'link': 886,\n 'drake': 887,\n 'meek': 888,\n 'gbbo': 889,\n 'houses': 890,\n 'become': 891,\n 'chance': 892,\n 'friends': 893,\n 'bbc': 894,\n 'cnn': 895,\n 'ignition': 896,\n '18': 897,\n 'myanmar': 898,\n 'try': 899,\n 'wanted': 900,\n 'chicago': 901,\n 'thousands': 902,\n 'alone': 903,\n 'climate': 904,\n 'yours': 905,\n 'else': 906,\n '24': 907,\n 'happened': 908,\n 'drive': 909,\n 'couple': 910,\n 'dog': 911,\n 'radio': 912,\n 'totally': 913,\n 'russia': 914,\n '100': 915,\n 'learn': 916,\n 'truth': 917,\n 'beach': 918,\n 'reports': 919,\n 'christian': 920,\n 'muslims': 921,\n 'temple': 922,\n 'mount': 923,\n 'view': 924,\n 'eye': 925,\n 'taken': 926,\n 'playing': 927,\n 'mishaps': 928,\n 'public': 929,\n 'mad': 930,\n 'cake': 931,\n 'pain': 932,\n 'large': 933,\n 'ladies': 934,\n 'appears': 935,\n 'centre': 936,\n 'village': 937,\n 'alarm': 938,\n 'takes': 939,\n 'issued': 940,\n 'emmerdale': 941,\n 'declaration': 942,\n 'disea': 943,\n 'sky': 944,\n 'front': 945,\n 'global': 946,\n 'experts': 947,\n 'france': 948,\n 'early': 949,\n 'trust': 950,\n 'israel': 951,\n 'ready': 952,\n 'vs': 953,\n 'human': 954,\n 'film': 955,\n 'till': 956,\n 'friend': 957,\n 'green': 958,\n 'driving': 959,\n 'favorite': 960,\n 'germs': 961,\n 'ain': 962,\n 'info': 963,\n 'womens': 964,\n 'middle': 965,\n 'marks': 966,\n 'thursday': 967,\n 'nagasaki': 968,\n 'downtown': 969,\n 'insurance': 970,\n 'mph': 971,\n 'british': 972,\n 'instead': 973,\n 'coaches': 974,\n 'sea': 975,\n 'flight': 976,\n 'quiz': 977,\n 'virgin': 978,\n 'chile': 979,\n 'bring': 980,\n 'taking': 981,\n 'reported': 982,\n 'dies': 983,\n 'turned': 984,\n 'moment': 985,\n 'behind': 986,\n 'four': 987,\n 'wednesday': 988,\n 'driver': 989,\n 'park': 990,\n 'following': 991,\n 'disease': 992,\n 'comes': 993,\n 'scared': 994,\n 'escape': 995,\n 'date': 996,\n 'hiring': 997,\n 'true': 998,\n 'theater': 999,\n 'gave': 1000,\n ...}"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets_ints[10]","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"[574, 62, 640, 23, 4, 275, 461, 35, 641]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def pad_features(tweets_ints, seq_length=280):\n    ''' Return features of tweets_ints, where each review is padded with 0's \n        or truncated to the input seq_length.\n        the default value us taken 280 as the size of a tweet is max 280\n    '''\n    \n    # getting the correct rows x cols shape\n    features = np.zeros((len(tweets_ints), seq_length), dtype=int)\n\n    # for each tweet, I grab that tweet and \n    for i, row in enumerate(tweets_ints):\n        features[i, -len(row):] = np.array(row)[:seq_length]\n    \n    return features","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = pad_features(tweets_ints, seq_length=100)\nfeatures[10]","execution_count":12,"outputs":[{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n       574,  62, 640,  23,   4, 275, 461,  35, 641])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"split_frac = 0.8\n\n## split data into training, validation, and test data (features and labels, x and y)\n\ntarget_labels = np.array(train_df.target)\nsplit_idx = int(len(features)*split_frac)\ntrain_x, remaining_x = features[:split_idx], features[split_idx:]\ntrain_y, remaining_y = target_labels[:split_idx], target_labels[split_idx:]\n\ntest_idx = int(len(remaining_x)*0.5)\nval_x, test_x = remaining_x[:test_idx], remaining_x[test_idx:]\nval_y, test_y = remaining_y[:test_idx], remaining_y[test_idx:]\n\n## print out the shapes of your resultant feature data\nprint(\"\\t\\t\\tFeature Shapes:\")\nprint(\"Train set: \\t\\t{}\".format(train_x.shape), \n      \"\\nValidation set: \\t{}\".format(val_x.shape),\n      \"\\nTest set: \\t\\t{}\".format(test_x.shape))","execution_count":13,"outputs":[{"output_type":"stream","text":"\t\t\tFeature Shapes:\nTrain set: \t\t(6090, 100) \nValidation set: \t(761, 100) \nTest set: \t\t(762, 100)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nfrom torch.utils.data import TensorDataset, DataLoader\n\n# create Tensor datasets\ntrain_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\nvalid_data = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\ntest_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n\n# dataloaders\nbatch_size = 50\n\n# to shuffle training data\ntrain_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, drop_last=True)\nvalid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size, drop_last=True)\ntest_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size, drop_last=True)","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get one batch of data\ndataiter = iter(train_loader)\nsample_x, sample_y = dataiter.next()\n\nprint('Sample input size: ', sample_x.size()) # batch_size, seq_length\nprint('Sample input: \\n', sample_x)\nprint()\nprint('Sample label size: ', sample_y.size()) # batch_size\nprint('Sample label: \\n', sample_y)","execution_count":15,"outputs":[{"output_type":"stream","text":"Sample input size:  torch.Size([50, 100])\nSample input: \n tensor([[    0,     0,     0,  ...,     1,     2, 14999],\n        [    0,     0,     0,  ...,  1128,   232,  2035],\n        [    0,     0,     0,  ...,    19,     5, 14999],\n        ...,\n        [    0,     0,     0,  ...,  7231,    57,   305],\n        [    0,     0,     0,  ...,    69,     4, 13598],\n        [    0,     0,     0,  ...,   628, 14999,   889]])\n\nSample label size:  torch.Size([50])\nSample label: \n tensor([1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n        0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0,\n        0, 1])\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_on_gpu=torch.cuda.is_available()\n\nif(train_on_gpu):\n    print('Training on GPU.')\nelse:\n    print('No GPU available, training on CPU.')","execution_count":16,"outputs":[{"output_type":"stream","text":"No GPU available, training on CPU.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.nn as nn\n\nclass SentimentRNN(nn.Module):\n    \"\"\"\n    The RNN model that will be used to perform Sentiment analysis.\n    \"\"\"\n\n    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n        \"\"\"\n        Initialize the model by setting up the layers.\n        \"\"\"\n        super(SentimentRNN, self).__init__()\n\n        self.output_size = output_size\n        self.n_layers = n_layers\n        self.hidden_dim = hidden_dim\n        \n        # embedding and LSTM layers\n        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n                            dropout=drop_prob, batch_first=True)\n        \n        # dropout layer\n        self.dropout = nn.Dropout(0.3)\n        \n        # linear and sigmoid layers\n        self.fc = nn.Linear(hidden_dim, output_size)\n        self.sig = nn.Sigmoid()\n        \n\n    def forward(self, x, hidden):\n        \"\"\"\n        Perform a forward pass of our model on some input and hidden state.\n        \"\"\"\n        batch_size = x.size(0)\n\n        # embeddings and lstm_out\n        x = x.long()\n        embeds = self.embedding(x)\n        lstm_out, hidden = self.lstm(embeds, hidden)\n    \n        # stack up lstm outputs\n        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n        \n        # dropout and fully-connected layer\n        out = self.dropout(lstm_out)\n        out = self.fc(out)\n        # sigmoid function\n        sig_out = self.sig(out)\n        \n        # reshape to be batch_size first\n        sig_out = sig_out.view(batch_size, -1)\n        sig_out = sig_out[:, -1] # get last batch of labels\n        \n        # return last sigmoid output and hidden state\n        return sig_out, hidden\n    \n    \n    def init_hidden(self, batch_size):\n        ''' Initializes hidden state '''\n        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n        # initialized to zero, for hidden state and cell state of LSTM\n        weight = next(self.parameters()).data\n        \n        if (train_on_gpu):\n            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n        else:\n            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n        \n        return hidden","execution_count":17,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* vocab_size: Size of our vocabulary or the range of values for our input, word tokens.\n* output_size: Size of our desired output; the number of class scores we want to output (pos/neg).\n* embedding_dim: Number of columns in the embedding lookup table; size of our embeddings.\n* hidden_dim: Number of units in the hidden layers of our LSTM cells. Usually larger is better performance wise. Common values are 128, 256, 512, etc.\n* n_layers: Number of LSTM layers in the network. Typically between 1-3"},{"metadata":{"trusted":true},"cell_type":"code","source":"vocab_size = len(vocab_to_int)+2 # +2 for the 0 padding and NO_WORD + our word tokens\noutput_size = 1\nembedding_dim = 400\nhidden_dim = 256\nn_layers = 3\n\nnet = SentimentRNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n\n\nprint(net)","execution_count":18,"outputs":[{"output_type":"stream","text":"SentimentRNN(\n  (embedding): Embedding(15000, 400)\n  (lstm): LSTM(400, 256, num_layers=3, batch_first=True, dropout=0.5)\n  (dropout): Dropout(p=0.3, inplace=False)\n  (fc): Linear(in_features=256, out_features=1, bias=True)\n  (sig): Sigmoid()\n)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train the model\nlr=0.001\n\ncriterion = nn.BCELoss()\noptimizer = torch.optim.Adam(net.parameters(), lr=lr)\n\nepochs = 6\n\ncounter = 0\nprint_every = 100\nclip=5 # gradient clipping\n\n# move model to GPU, if available\nif(train_on_gpu):\n    net.cuda()\n\nnet.train()\n\nfor e in range(epochs):\n    # initialize hidden state\n    \n    h = net.init_hidden(batch_size)\n\n    \n    \n    # batch loop\n    for inputs, labels in train_loader:\n        counter += 1\n\n        if(train_on_gpu):\n            inputs, labels = inputs.cuda(), labels.cuda()\n\n        # Creating new variables for the hidden state, otherwise\n        # we'd backprop through the entire training history\n        h = tuple([each.data for each in h])\n\n        # zero accumulated gradients\n        net.zero_grad()\n\n        # get the output from the model\n        output, h = net(inputs, h)\n\n        # calculate the loss and perform backprop\n        loss = criterion(output.squeeze(), labels.float())\n        loss.backward()\n        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n        nn.utils.clip_grad_norm_(net.parameters(), clip)\n        optimizer.step()\n\n        # loss stats\n        if counter % print_every == 0:\n            # Get validation loss\n            val_h = net.init_hidden(batch_size)\n            val_losses = []\n            net.eval()\n            for inputs, labels in valid_loader:\n\n                # Creating new variables for the hidden state, otherwise\n                # we'd backprop through the entire training history\n                val_h = tuple([each.data for each in val_h])\n                \n\n                if(train_on_gpu):\n                    inputs, labels = inputs.cuda(), labels.cuda()\n\n                output, val_h = net(inputs, val_h)\n                val_loss = criterion(output.squeeze(), labels.float())\n\n                val_losses.append(val_loss.item())\n\n            net.train()\n            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n                  \"Step: {}...\".format(counter),\n                  \"Loss: {:.6f}...\".format(loss.item()),\n                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))","execution_count":19,"outputs":[{"output_type":"stream","text":"Epoch: 1/6... Step: 100... Loss: 0.509465... Val Loss: 0.547702\nEpoch: 2/6... Step: 200... Loss: 0.352670... Val Loss: 0.556884\nEpoch: 3/6... Step: 300... Loss: 0.284272... Val Loss: 0.539507\nEpoch: 4/6... Step: 400... Loss: 0.333691... Val Loss: 0.671217\nEpoch: 5/6... Step: 500... Loss: 0.092468... Val Loss: 0.757905\nEpoch: 5/6... Step: 600... Loss: 0.122831... Val Loss: 0.772994\nEpoch: 6/6... Step: 700... Loss: 0.251526... Val Loss: 1.012983\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get test data loss and accuracy\n\ntest_losses = [] # track loss\nnum_correct = 0\n\n# init hidden state\nh = net.init_hidden(batch_size)\n\nnet.eval()\n# iterate over test data\nfor inputs, labels in test_loader:\n\n    # Creating new variables for the hidden state, otherwise\n    # we'd backprop through the entire training history\n    h = tuple([each.data for each in h])\n\n    if(train_on_gpu):\n        inputs, labels = inputs.cuda(), labels.cuda()\n    \n    # get predicted outputs\n    output, h = net(inputs, h)\n    \n    # calculate loss\n    test_loss = criterion(output.squeeze(), labels.float())\n    test_losses.append(test_loss.item())\n    \n    # convert output probabilities to predicted class (0 or 1)\n    pred = torch.round(output.squeeze())  # rounds to the nearest integer\n    \n    # compare predictions to true label\n    correct_tensor = pred.eq(labels.float().view_as(pred))\n    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n    num_correct += np.sum(correct)\n\n\n# -- stats! -- ##\n# avg test loss\nprint(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n\n# accuracy over all test data\ntest_acc = num_correct/len(test_loader.dataset)\nprint(\"Test accuracy: {:.3f}\".format(test_acc))","execution_count":20,"outputs":[{"output_type":"stream","text":"Test loss: 0.814\nTest accuracy: 0.740\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test model on a single tweet\nnew_tweet = 'heavy rainfall. people are drowning'\n\nnew_tweet = format_tweets(new_tweet)\n\nint_tweets = []\nnew_tweet_to_int = [0] * len(new_tweet.split())\n\nidx = 0\nfor word in new_tweet.split():\n    \n    new_tweet_to_int[idx] = vocab_to_int[word] if word in vocab_to_int else NO_WORD # giving a value 14999 if the word is not in the vocab\n    idx += 1\n        \n\nint_tweets.append(new_tweet_to_int)\nint_tweets","execution_count":21,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"[[826, 4112, 62, 26, 479]]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"seq_length=100\nfeatures = pad_features(int_tweets, seq_length)\n\nprint(features)","execution_count":22,"outputs":[{"output_type":"stream","text":"[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0  826 4112   62\n    26  479]]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_tensor = torch.from_numpy(features)\nprint(feature_tensor.size())\n\nbatch_size = feature_tensor.size(0)\nh = net.init_hidden(batch_size)\n\nif(train_on_gpu):\n    feature_tensor = feature_tensor.cuda()\n\noutput, h = net(feature_tensor, h)\npred = torch.round(output.squeeze())\npred.item()","execution_count":23,"outputs":[{"output_type":"stream","text":"torch.Size([1, 100])\n","name":"stdout"},{"output_type":"execute_result","execution_count":23,"data":{"text/plain":"1.0"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting the result of the final test data \n\ndef predict(net, int_tweets, seq_length=280):\n\n    # pad to seq length\n    features = pad_features(int_tweets, seq_length)\n    \n    feature_tensor = torch.from_numpy(features)\n\n    batch_size = feature_tensor.size(0)\n    h = net.init_hidden(batch_size)\n\n    if(train_on_gpu):\n        feature_tensor = feature_tensor.cuda()\n\n    output, h = net(feature_tensor, h)\n    pred = torch.round(output.squeeze())\n    \n    return pred.item()\n    ","execution_count":24,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert all tweet to int and send it to predict function\n\npredictions = []\n\nfor tweet in out_df.text:\n    \n    \n    tweet = format_tweets(tweet)\n \n    int_tweets = []\n    tweet_to_int = [0] * len(tweet.split())\n    \n    \n    idx = 0\n    for word in tweet.split():\n    \n        tweet_to_int[idx] = vocab_to_int[word] if word in vocab_to_int else NO_WORD # giving a value 9999 if the word is not in the vocab\n        idx += 1\n        \n    # tweet to integers\n    int_tweets.append(tweet_to_int)\n    predictions.append(predict(net, int_tweets, seq_length=100))\n    \n\npredictions[:50]","execution_count":25,"outputs":[{"output_type":"execute_result","execution_count":25,"data":{"text/plain":"[0.0,\n 1.0,\n 1.0,\n 1.0,\n 1.0,\n 0.0,\n 0.0,\n 0.0,\n 0.0,\n 0.0,\n 0.0,\n 0.0,\n 0.0,\n 0.0,\n 0.0,\n 1.0,\n 0.0,\n 1.0,\n 0.0,\n 0.0,\n 0.0,\n 0.0,\n 0.0,\n 1.0,\n 0.0,\n 0.0,\n 0.0,\n 0.0,\n 0.0,\n 1.0,\n 0.0,\n 0.0,\n 0.0,\n 0.0,\n 1.0,\n 0.0,\n 1.0,\n 1.0,\n 0.0,\n 1.0,\n 0.0,\n 0.0,\n 1.0,\n 0.0,\n 0.0,\n 0.0,\n 0.0,\n 0.0,\n 1.0,\n 0.0]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pandas import DataFrame\n\nfinal_preds['id'] = out_df['id']\nfinal_preds['target'] = DataFrame(predictions)\n\nfinal_preds = final_preds[['id', 'target']]\n\nfinal_preds.to_csv('output.csv',index=False)\nfinal_preds.head()","execution_count":40,"outputs":[{"output_type":"execute_result","execution_count":40,"data":{"text/plain":"   id  target\n0   0     0.0\n1   2     1.0\n2   3     1.0\n3   9     1.0\n4  11     1.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_preds.shape","execution_count":33,"outputs":[{"output_type":"execute_result","execution_count":33,"data":{"text/plain":"(3263, 1)"},"metadata":{}}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat":4,"nbformat_minor":4}